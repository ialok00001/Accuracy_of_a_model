{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d6a50ed",
   "metadata": {},
   "source": [
    "### Measuring the accuracy of a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2c60a2",
   "metadata": {},
   "source": [
    "Usually, one of the category in which we are classifying the input data (assuming binary classification) is extremely rare. For example, in credit card cases, less than 0.1% are actually fraud. Hence if we classify each transaction as a \"No\", i.e., it is not a fraud and a valid card transaction, then we will be right more than 99.9% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fa555b",
   "metadata": {},
   "source": [
    "Side Note:- This has some adverse implications. If we start classifying each transaction as not a fraud, then soon this news will be spread among everyone in the world. People will start making illegal transactions, since no one is actually classifying them as a fraud. This will eventually lead to a rise in cases of credit card frauds and there will be an economical breakdown all around the world.\n",
    "\n",
    "Hence a credit card fraud classifying system must be present to prevent this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19f7e42",
   "metadata": {},
   "source": [
    "We will assume that the category \"Yes\" is in minority."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad1b4b3",
   "metadata": {},
   "source": [
    "We want to classify as many \"Yes\" cases as possible, i.e., in the credit card cases trying to catch as many \"Yes\" from those 0.1% case as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1172cfd5",
   "metadata": {},
   "source": [
    "Now, some cases will be very easy to classify as \"Yes\" or a \"No\" by the model. But there will be some other cases that can be marked either, based on its probability. We call them the borderline cases.\n",
    "\n",
    "It is these cases on which we work to improve our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0b69e7",
   "metadata": {},
   "source": [
    "#### Aggressive Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965d0f8c",
   "metadata": {},
   "source": [
    "Classifying every borderline cases (or at least most of them) as \"Yes\" (the minority one).\n",
    "\n",
    "This results in False positives.\n",
    "\n",
    "This classifier focuses on increasing the fraction of Actual Positive cases which were classified Positive. This classifier is used where classifying something as false Positive will not cause much problem but classifying something as a false Negative can cause serious problems.\n",
    "\n",
    "Example 1:\n",
    "In credit card case, if we classify a transaction as fraud (Positive) even if it was not, it will not cause any major problem since it can later be corrected after further checking. But if we classify a fraud as Negative, then that can cause mojor loss to the customers since they will be loosing heavy amount of money from their account.\n",
    "\n",
    "Example 2:\n",
    "In COVID-19 cases, if we classify someone who dosent have covid as Positive, initial precautions can be taken by that individual and the mistake can be rectified by further careful examinations. But if someone who is actually positive is classified as Negative, then the individual will be an obvious carrier of the virus, not detected by anyone and hence causing unexpected rise in multiple cases.\n",
    "\n",
    "Example 3:\n",
    "During the screening test taken by any college, a post or a company, they don't want to loose any potential candidate. Hence they will be making the screening in such a way that even if someone is not worthy is also selected, due to borderline case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3081780f",
   "metadata": {},
   "source": [
    "#### Cautious Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a411525",
   "metadata": {},
   "source": [
    "Classifying borderline cases as \"No\". This classifier mostly focuses on making 'cautious' decision is choosing a positive. During this, it can even classify something as a Negative even if it was positive. It is used in the areas where the selection of a Positive has to be made very carefully.\n",
    "\n",
    "This results in False Negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f6425",
   "metadata": {},
   "source": [
    "Example 1:\n",
    "For selecting someone for college, post or a company, the interviewers want to select only the 'truly deserving' candidates as the number of posts available is far less than the number of ones applied. Hence they will try to reduce their choice by marking most of the borderline cases as Negative.\n",
    "\n",
    "(Note that both the classifiers can be used simultaneously, like Example 3 in Aggressive Classifier and Example 1 in Cautious Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca2b27f",
   "metadata": {},
   "source": [
    "There are two ways in classifying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a32872",
   "metadata": {},
   "source": [
    "###### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de848362",
   "metadata": {},
   "source": [
    "Out of the cases which are \"classified\" positive, how many of them are actually positive.\n",
    "$$$$\n",
    "\n",
    "\n",
    "$$\\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7005a4",
   "metadata": {},
   "source": [
    "###### Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a8b633",
   "metadata": {},
   "source": [
    "Out of the cases which are \"actual\" positive, how many of them classified positive.\n",
    "$$$$\n",
    "\n",
    "\n",
    "$$\\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37714c6",
   "metadata": {},
   "source": [
    "###### Precision vs Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64e7316",
   "metadata": {},
   "source": [
    "Precision and Recall both are inversely related, i.e., if we try to increase one of them then the other one must decrease. This is evident from the above discussions and the fact that we cannot make a classifier that is both Aggresive and Cautious at the same time.\n",
    "\n",
    "- Increasing Precision would mean making a more Cautious Classifier.\n",
    "- Increasing Recall would mean making a more Aggressive Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6467605a",
   "metadata": {},
   "source": [
    "Which kind of classifier to use depends upon the kind of problem and the dataset we are dealing with. Although, we can make a classifier that is a `trade-off` between both the kinds, i.e., a classifier that is Aggressive enough to classify many inputs as positives, yet Cautious enough to reduce the mistakes in making such decisions. To achieve this, we can use another metric that tries to maximize both Precision and Recall at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b18e6fc",
   "metadata": {},
   "source": [
    "###### f1 Score\n",
    "\n",
    "The f1 score or the F score is defined as the harmonic mean of Precision and Recall.\n",
    "$$$$\n",
    "\n",
    "$$\\text{f1 score} = \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
